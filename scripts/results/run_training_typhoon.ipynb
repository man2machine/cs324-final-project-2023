{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = \"C:/HF_CACHE/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from cs324_project.datasets import GlueDatasetTask, load_glue_dataset_info\n",
    "from cs324_project.models import ModelCheckpointName, load_classification_model, load_pretraining_model, load_tokenizer\n",
    "from cs324_project.masking import (\n",
    "    get_training_args_mlm, get_trainer_mlm, RandomMaskingConfig, WholeWordMaskingConfig, TyphoonMaskingConfig)\n",
    "from cs324_project.classification import get_training_args_sc, get_trainer_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ModelCheckpointName.TINYBERT_HUAWEI\n",
    "task = GlueDatasetTask.MRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/HF_CACHE/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08df91e0c8b4c34a03f6a80c3109fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = load_tokenizer(model_name)\n",
    "dataset_info = load_glue_dataset_info(task, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune with masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertForMaskedLM: ['fit_denses.2.weight', 'cls.seq_relationship.bias', 'fit_denses.4.weight', 'fit_denses.3.bias', 'fit_denses.1.weight', 'fit_denses.2.bias', 'fit_denses.0.bias', 'fit_denses.1.bias', 'fit_denses.3.weight', 'cls.seq_relationship.weight', 'fit_denses.0.weight', 'fit_denses.4.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_mlm = load_pretraining_model(model_name, dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training arguments, model output dir: C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 11-22-37 AM\n"
     ]
    }
   ],
   "source": [
    "training_args_mlm = get_training_args_mlm(\n",
    "    masking_config=TyphoonMaskingConfig(),\n",
    "    num_epochs=100)\n",
    "trainer_mlm = get_trainer_mlm(\n",
    "    dataset_info=dataset_info,\n",
    "    mlm_args=training_args_mlm,\n",
    "    model=model_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23000' max='23000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23000/23000 23:50, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.431400</td>\n",
       "      <td>5.714137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.210800</td>\n",
       "      <td>4.945677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.706200</td>\n",
       "      <td>4.574192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.363100</td>\n",
       "      <td>4.323779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.137800</td>\n",
       "      <td>4.185390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.953700</td>\n",
       "      <td>3.983167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.794200</td>\n",
       "      <td>3.920470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.638600</td>\n",
       "      <td>3.790572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.578800</td>\n",
       "      <td>3.812777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.444600</td>\n",
       "      <td>3.732371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.351300</td>\n",
       "      <td>3.611592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.264500</td>\n",
       "      <td>3.661664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.200900</td>\n",
       "      <td>3.613808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.113900</td>\n",
       "      <td>3.476422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.067800</td>\n",
       "      <td>3.488884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.028000</td>\n",
       "      <td>3.505734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.964300</td>\n",
       "      <td>3.507443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.884500</td>\n",
       "      <td>3.478958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.826900</td>\n",
       "      <td>3.600201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.812300</td>\n",
       "      <td>3.508568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.764000</td>\n",
       "      <td>3.511130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.727500</td>\n",
       "      <td>3.373178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.672700</td>\n",
       "      <td>3.465063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.632400</td>\n",
       "      <td>3.412465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.585300</td>\n",
       "      <td>3.417115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.578100</td>\n",
       "      <td>3.298543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.537400</td>\n",
       "      <td>3.402269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.515500</td>\n",
       "      <td>3.340516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.454600</td>\n",
       "      <td>3.420413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.433100</td>\n",
       "      <td>3.307008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.387100</td>\n",
       "      <td>3.486843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.386500</td>\n",
       "      <td>3.463908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.375600</td>\n",
       "      <td>3.409691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.333600</td>\n",
       "      <td>3.341757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.269600</td>\n",
       "      <td>3.421290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.270600</td>\n",
       "      <td>3.290917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>2.266900</td>\n",
       "      <td>3.465626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.243200</td>\n",
       "      <td>3.343371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.199100</td>\n",
       "      <td>3.348472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.199100</td>\n",
       "      <td>3.436975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2.146500</td>\n",
       "      <td>3.513528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.134600</td>\n",
       "      <td>3.363099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2.123600</td>\n",
       "      <td>3.335773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.098000</td>\n",
       "      <td>3.367947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.084600</td>\n",
       "      <td>3.342101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.084100</td>\n",
       "      <td>3.309452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.057800</td>\n",
       "      <td>3.381619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.043900</td>\n",
       "      <td>3.388430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2.025700</td>\n",
       "      <td>3.275054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.988700</td>\n",
       "      <td>3.445660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.994100</td>\n",
       "      <td>3.390356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.970200</td>\n",
       "      <td>3.372145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.957800</td>\n",
       "      <td>3.398864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.949700</td>\n",
       "      <td>3.492792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.941000</td>\n",
       "      <td>3.429517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.921300</td>\n",
       "      <td>3.374901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.915000</td>\n",
       "      <td>3.340762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.874700</td>\n",
       "      <td>3.465828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.860600</td>\n",
       "      <td>3.340350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.857500</td>\n",
       "      <td>3.333278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.849000</td>\n",
       "      <td>3.505683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.839000</td>\n",
       "      <td>3.380217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.844000</td>\n",
       "      <td>3.471811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.811300</td>\n",
       "      <td>3.351989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.805800</td>\n",
       "      <td>3.460276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.793900</td>\n",
       "      <td>3.304482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.776900</td>\n",
       "      <td>3.338570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>3.503991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.751100</td>\n",
       "      <td>3.383313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.761600</td>\n",
       "      <td>3.394622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.740800</td>\n",
       "      <td>3.416636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.751600</td>\n",
       "      <td>3.522201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.735900</td>\n",
       "      <td>3.382389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.713400</td>\n",
       "      <td>3.405652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.683300</td>\n",
       "      <td>3.286829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.680100</td>\n",
       "      <td>3.416019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.699300</td>\n",
       "      <td>3.403870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.682900</td>\n",
       "      <td>3.436988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.675300</td>\n",
       "      <td>3.340814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.665100</td>\n",
       "      <td>3.436940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.674600</td>\n",
       "      <td>3.421338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.640500</td>\n",
       "      <td>3.313693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.657600</td>\n",
       "      <td>3.377894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.629500</td>\n",
       "      <td>3.519563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.621700</td>\n",
       "      <td>3.335718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.631500</td>\n",
       "      <td>3.410574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>3.297465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.623600</td>\n",
       "      <td>3.352165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>1.619000</td>\n",
       "      <td>3.284204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.624300</td>\n",
       "      <td>3.311070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.604200</td>\n",
       "      <td>3.499874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.580400</td>\n",
       "      <td>3.318519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.600700</td>\n",
       "      <td>3.329772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.580400</td>\n",
       "      <td>3.410891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.604400</td>\n",
       "      <td>3.398114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.589100</td>\n",
       "      <td>3.292952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.572800</td>\n",
       "      <td>3.324104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.582500</td>\n",
       "      <td>3.434238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.586300</td>\n",
       "      <td>3.402344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.586500</td>\n",
       "      <td>3.413042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=23000, training_loss=2.2991143931513247, metrics={'train_runtime': 1431.9086, 'train_samples_per_second': 256.162, 'train_steps_per_second': 16.062, 'total_flos': 786121535232432.0, 'train_loss': 2.2991143931513247, 'epoch': 100.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_mlm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.381281852722168,\n",
       " 'eval_runtime': 0.4757,\n",
       " 'eval_samples_per_second': 857.739,\n",
       " 'eval_steps_per_second': 54.66,\n",
       " 'epoch': 100.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_mlm.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 11-22-37 AM\\checkpoint-11270\n"
     ]
    }
   ],
   "source": [
    "print(trainer_mlm.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune on sequence classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 11-22-37 AM\\checkpoint-11270 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 11-22-37 AM\\checkpoint-11270 and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_sc = load_classification_model(trainer_mlm.state.best_model_checkpoint, dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training arguments, model output dir: C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\sc\\Model 03-21-2023 11-46-31 AM\n"
     ]
    }
   ],
   "source": [
    "training_args_sc = get_training_args_sc(\n",
    "    task,\n",
    "    num_epochs=100)\n",
    "trainer_sc = get_trainer_sc(\n",
    "    dataset_info=dataset_info,\n",
    "    model=model_sc,\n",
    "    training_args=training_args_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23000' max='23000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23000/23000 16:43, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.665600</td>\n",
       "      <td>0.631107</td>\n",
       "      <td>0.683824</td>\n",
       "      <td>0.812227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.627200</td>\n",
       "      <td>0.608966</td>\n",
       "      <td>0.683824</td>\n",
       "      <td>0.812227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.612900</td>\n",
       "      <td>0.600260</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.603400</td>\n",
       "      <td>0.593078</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.595400</td>\n",
       "      <td>0.586084</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.818316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.586400</td>\n",
       "      <td>0.578768</td>\n",
       "      <td>0.700980</td>\n",
       "      <td>0.819527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.579700</td>\n",
       "      <td>0.570612</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.817778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.569000</td>\n",
       "      <td>0.562677</td>\n",
       "      <td>0.703431</td>\n",
       "      <td>0.818591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.560400</td>\n",
       "      <td>0.554392</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.824242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.551500</td>\n",
       "      <td>0.546068</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.823708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.539800</td>\n",
       "      <td>0.537386</td>\n",
       "      <td>0.718137</td>\n",
       "      <td>0.824962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.531800</td>\n",
       "      <td>0.531871</td>\n",
       "      <td>0.718137</td>\n",
       "      <td>0.824427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.524300</td>\n",
       "      <td>0.522937</td>\n",
       "      <td>0.723039</td>\n",
       "      <td>0.824806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.513700</td>\n",
       "      <td>0.519096</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.829953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.506500</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0.742647</td>\n",
       "      <td>0.834646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.499100</td>\n",
       "      <td>0.508604</td>\n",
       "      <td>0.767157</td>\n",
       "      <td>0.846029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.494500</td>\n",
       "      <td>0.505685</td>\n",
       "      <td>0.769608</td>\n",
       "      <td>0.846405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>0.502517</td>\n",
       "      <td>0.776961</td>\n",
       "      <td>0.848586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.483500</td>\n",
       "      <td>0.500727</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.850993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.477100</td>\n",
       "      <td>0.498199</td>\n",
       "      <td>0.772059</td>\n",
       "      <td>0.844741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.496486</td>\n",
       "      <td>0.776961</td>\n",
       "      <td>0.848080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.465800</td>\n",
       "      <td>0.494584</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.845118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.456300</td>\n",
       "      <td>0.493322</td>\n",
       "      <td>0.776961</td>\n",
       "      <td>0.846024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.492770</td>\n",
       "      <td>0.776961</td>\n",
       "      <td>0.843911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.491684</td>\n",
       "      <td>0.781863</td>\n",
       "      <td>0.846816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.444300</td>\n",
       "      <td>0.489985</td>\n",
       "      <td>0.781863</td>\n",
       "      <td>0.846816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.434700</td>\n",
       "      <td>0.489741</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.843206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.431700</td>\n",
       "      <td>0.487982</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.849220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.429700</td>\n",
       "      <td>0.488015</td>\n",
       "      <td>0.757353</td>\n",
       "      <td>0.824779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.424200</td>\n",
       "      <td>0.486390</td>\n",
       "      <td>0.759804</td>\n",
       "      <td>0.826855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>0.486710</td>\n",
       "      <td>0.757353</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.418300</td>\n",
       "      <td>0.485772</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.822064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.418900</td>\n",
       "      <td>0.484657</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.817857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.486645</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.815884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.402500</td>\n",
       "      <td>0.484913</td>\n",
       "      <td>0.752451</td>\n",
       "      <td>0.818018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>0.486875</td>\n",
       "      <td>0.752451</td>\n",
       "      <td>0.817360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.395900</td>\n",
       "      <td>0.485379</td>\n",
       "      <td>0.757353</td>\n",
       "      <td>0.821622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.486682</td>\n",
       "      <td>0.757353</td>\n",
       "      <td>0.820976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.386800</td>\n",
       "      <td>0.492602</td>\n",
       "      <td>0.747549</td>\n",
       "      <td>0.811009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.495897</td>\n",
       "      <td>0.747549</td>\n",
       "      <td>0.808905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>0.490332</td>\n",
       "      <td>0.752451</td>\n",
       "      <td>0.815356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.497802</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>0.490502</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.813187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>0.494299</td>\n",
       "      <td>0.752451</td>\n",
       "      <td>0.813996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.379900</td>\n",
       "      <td>0.491595</td>\n",
       "      <td>0.752451</td>\n",
       "      <td>0.814679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.362900</td>\n",
       "      <td>0.494446</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.365200</td>\n",
       "      <td>0.495211</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.808118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.366100</td>\n",
       "      <td>0.502087</td>\n",
       "      <td>0.742647</td>\n",
       "      <td>0.803738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.501992</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.805243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.497871</td>\n",
       "      <td>0.742647</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.359100</td>\n",
       "      <td>0.502332</td>\n",
       "      <td>0.747549</td>\n",
       "      <td>0.806754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.503513</td>\n",
       "      <td>0.747549</td>\n",
       "      <td>0.806754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.502027</td>\n",
       "      <td>0.747549</td>\n",
       "      <td>0.806754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.353800</td>\n",
       "      <td>0.510021</td>\n",
       "      <td>0.742647</td>\n",
       "      <td>0.801512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.343700</td>\n",
       "      <td>0.508374</td>\n",
       "      <td>0.747549</td>\n",
       "      <td>0.806026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.505158</td>\n",
       "      <td>0.747549</td>\n",
       "      <td>0.806026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.349300</td>\n",
       "      <td>0.503912</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.804511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.506642</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.803774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.510486</td>\n",
       "      <td>0.737745</td>\n",
       "      <td>0.796964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.334900</td>\n",
       "      <td>0.511658</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.794677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.335200</td>\n",
       "      <td>0.507223</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.794727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>0.511420</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.794677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.333700</td>\n",
       "      <td>0.515481</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.794677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.334900</td>\n",
       "      <td>0.517969</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.794677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.516732</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.794677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.340400</td>\n",
       "      <td>0.522822</td>\n",
       "      <td>0.727941</td>\n",
       "      <td>0.786127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.519819</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.792381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.324400</td>\n",
       "      <td>0.519719</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.792381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.524863</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.789272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.320400</td>\n",
       "      <td>0.527911</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.788462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.322700</td>\n",
       "      <td>0.529134</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.788462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.321500</td>\n",
       "      <td>0.524436</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.790076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.319600</td>\n",
       "      <td>0.528691</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.790787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.318500</td>\n",
       "      <td>0.529345</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.789272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.533454</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.788462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.322200</td>\n",
       "      <td>0.537953</td>\n",
       "      <td>0.727941</td>\n",
       "      <td>0.784466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.533940</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.789981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.316300</td>\n",
       "      <td>0.537555</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.789168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.317200</td>\n",
       "      <td>0.536876</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.789168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.314600</td>\n",
       "      <td>0.536509</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.789168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.313100</td>\n",
       "      <td>0.536037</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.791506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.314200</td>\n",
       "      <td>0.536697</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.789168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.535476</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.791506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.317600</td>\n",
       "      <td>0.533655</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.788462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.534241</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.788462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.310200</td>\n",
       "      <td>0.536159</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.789981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.306800</td>\n",
       "      <td>0.537114</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.789981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.537582</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.789981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.308800</td>\n",
       "      <td>0.537421</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.789981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.309900</td>\n",
       "      <td>0.541030</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.789168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.300800</td>\n",
       "      <td>0.539658</td>\n",
       "      <td>0.732843</td>\n",
       "      <td>0.789981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.541455</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.787645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.302600</td>\n",
       "      <td>0.541863</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.787645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.304100</td>\n",
       "      <td>0.541661</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.787645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.542068</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.787645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.542407</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.787645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.308100</td>\n",
       "      <td>0.543323</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.787645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.307400</td>\n",
       "      <td>0.544004</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.790698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.544283</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.790698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.307800</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.790698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=23000, training_loss=0.39363236800484036, metrics={'train_runtime': 1003.421, 'train_samples_per_second': 365.549, 'train_steps_per_second': 22.922, 'total_flos': 781014765977712.0, 'train_loss': 0.39363236800484036, 'epoch': 100.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_sc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4879816174507141,\n",
       " 'eval_accuracy': 0.7867647058823529,\n",
       " 'eval_f1': 0.8492201039861352,\n",
       " 'eval_runtime': 0.5086,\n",
       " 'eval_samples_per_second': 802.149,\n",
       " 'eval_steps_per_second': 51.117,\n",
       " 'epoch': 100.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_sc.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\sc\\Model 03-21-2023 11-46-31 AM\\checkpoint-6440\n"
     ]
    }
   ],
   "source": [
    "print(trainer_sc.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1c2f54458d7f848ec1fcb01a8862cbba54f8bc5c8c8ff3352654112e2f5a13a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
