{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = \"C:/HF_CACHE/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from cs324_project.datasets import GlueDatasetTask, load_glue_dataset_info\n",
    "from cs324_project.models import ModelCheckpointName, load_classification_model, load_pretraining_model, load_tokenizer\n",
    "from cs324_project.masking import (\n",
    "    get_training_args_mlm, get_trainer_mlm, RandomMaskingConfig, WholeWordMaskingConfig, TyphoonMaskingConfig)\n",
    "from cs324_project.classification import get_training_args_sc, get_trainer_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ModelCheckpointName.TINYBERT_HUAWEI\n",
    "task = GlueDatasetTask.COLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/HF_CACHE/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0276141dca4f6abb55624e7a5b9036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-51f5b2c7a7ff1e58.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-02d0d32fa3df3a08.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-37efad78792ce9c4.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-df985a2934c3ba2f.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-b2e1d3e57836d04c.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-598cd95f3828ee11.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenizer = load_tokenizer(model_name)\n",
    "dataset_info = load_glue_dataset_info(task, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune with masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertForMaskedLM: ['fit_denses.2.weight', 'fit_denses.4.bias', 'fit_denses.0.bias', 'fit_denses.3.bias', 'fit_denses.2.bias', 'fit_denses.1.bias', 'cls.seq_relationship.weight', 'fit_denses.4.weight', 'fit_denses.1.weight', 'cls.seq_relationship.bias', 'fit_denses.0.weight', 'fit_denses.3.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_mlm = load_pretraining_model(model_name, dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training arguments, model output dir: C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 10-50-00 PM\n"
     ]
    }
   ],
   "source": [
    "training_args_mlm = get_training_args_mlm(\n",
    "    masking_config=RandomMaskingConfig(),\n",
    "    num_epochs=80)\n",
    "trainer_mlm = get_trainer_mlm(\n",
    "    dataset_info=dataset_info,\n",
    "    mlm_args=training_args_mlm,\n",
    "    model=model_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42800' max='42800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42800/42800 25:13, Epoch 80/80]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.569100</td>\n",
       "      <td>3.982995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.825900</td>\n",
       "      <td>3.698572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.585300</td>\n",
       "      <td>3.621619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.408500</td>\n",
       "      <td>3.674379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.289300</td>\n",
       "      <td>3.419763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.150200</td>\n",
       "      <td>3.382149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.043400</td>\n",
       "      <td>3.414268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.946700</td>\n",
       "      <td>3.371143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.878800</td>\n",
       "      <td>3.358126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.787000</td>\n",
       "      <td>3.253760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.702000</td>\n",
       "      <td>3.300933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.630600</td>\n",
       "      <td>3.220606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.565200</td>\n",
       "      <td>3.322458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.515600</td>\n",
       "      <td>3.190812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.452900</td>\n",
       "      <td>3.187291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.387900</td>\n",
       "      <td>3.140112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.308400</td>\n",
       "      <td>3.188684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.286700</td>\n",
       "      <td>3.129734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.227600</td>\n",
       "      <td>3.092683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.162100</td>\n",
       "      <td>3.120438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.121300</td>\n",
       "      <td>3.140487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.067900</td>\n",
       "      <td>3.094951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.028900</td>\n",
       "      <td>3.030049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.966300</td>\n",
       "      <td>3.129529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.949400</td>\n",
       "      <td>3.191428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.898800</td>\n",
       "      <td>3.173617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.887700</td>\n",
       "      <td>3.119723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.824100</td>\n",
       "      <td>3.157964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.781400</td>\n",
       "      <td>3.117342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.775800</td>\n",
       "      <td>3.115601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.754700</td>\n",
       "      <td>3.111025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.700600</td>\n",
       "      <td>3.057196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.661500</td>\n",
       "      <td>3.046493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.613000</td>\n",
       "      <td>3.164663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.619500</td>\n",
       "      <td>3.005302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.606700</td>\n",
       "      <td>3.161267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.551300</td>\n",
       "      <td>3.148092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.544900</td>\n",
       "      <td>3.188979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.503500</td>\n",
       "      <td>3.130167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.504100</td>\n",
       "      <td>3.087960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.471800</td>\n",
       "      <td>3.100533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.460300</td>\n",
       "      <td>3.110150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.449000</td>\n",
       "      <td>3.126429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.382100</td>\n",
       "      <td>3.121172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.381400</td>\n",
       "      <td>3.229841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.366100</td>\n",
       "      <td>3.171377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.335200</td>\n",
       "      <td>3.139407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.332000</td>\n",
       "      <td>3.128441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.312700</td>\n",
       "      <td>3.103367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.287900</td>\n",
       "      <td>3.158568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.290900</td>\n",
       "      <td>3.230955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.261700</td>\n",
       "      <td>3.169076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.241200</td>\n",
       "      <td>3.145077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.240400</td>\n",
       "      <td>3.083190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.225400</td>\n",
       "      <td>3.212910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.219600</td>\n",
       "      <td>3.059529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.217200</td>\n",
       "      <td>3.183074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.184500</td>\n",
       "      <td>3.066512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.167300</td>\n",
       "      <td>3.090809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.169500</td>\n",
       "      <td>3.137618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.149600</td>\n",
       "      <td>3.115886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.127000</td>\n",
       "      <td>3.299823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.125700</td>\n",
       "      <td>3.135631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.118400</td>\n",
       "      <td>3.227419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.124400</td>\n",
       "      <td>3.165123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.106500</td>\n",
       "      <td>3.137748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.081800</td>\n",
       "      <td>3.156374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.089900</td>\n",
       "      <td>3.255960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.065400</td>\n",
       "      <td>3.226478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.062800</td>\n",
       "      <td>3.057981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.065800</td>\n",
       "      <td>3.172165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.048400</td>\n",
       "      <td>3.183522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.059300</td>\n",
       "      <td>3.147370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.050700</td>\n",
       "      <td>3.015100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.051600</td>\n",
       "      <td>3.180298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.023400</td>\n",
       "      <td>3.164676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.031900</td>\n",
       "      <td>3.214555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.032000</td>\n",
       "      <td>3.297500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.009500</td>\n",
       "      <td>3.238733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.014400</td>\n",
       "      <td>3.185608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=42800, training_loss=1.7564905284275518, metrics={'train_runtime': 1515.5566, 'train_samples_per_second': 451.372, 'train_steps_per_second': 28.24, 'total_flos': 399180875327136.0, 'train_loss': 1.7564905284275518, 'epoch': 80.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_mlm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.074653148651123,\n",
       " 'eval_runtime': 0.6772,\n",
       " 'eval_samples_per_second': 1540.194,\n",
       " 'eval_steps_per_second': 97.462,\n",
       " 'epoch': 80.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_mlm.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 10-50-00 PM\\checkpoint-18725\n"
     ]
    }
   ],
   "source": [
    "print(trainer_mlm.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune on sequence classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 10-50-00 PM\\checkpoint-18725 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 10-50-00 PM\\checkpoint-18725 and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_sc = load_classification_model(trainer_mlm.state.best_model_checkpoint, dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training arguments, model output dir: C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\sc\\Model 03-21-2023 11-15-16 PM\n"
     ]
    }
   ],
   "source": [
    "training_args_sc = get_training_args_sc(\n",
    "    task,\n",
    "    learning_rate=2e-5,\n",
    "    num_epochs=120)\n",
    "trainer_sc = get_trainer_sc(\n",
    "    dataset_info=dataset_info,\n",
    "    model=model_sc,\n",
    "    training_args=training_args_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64200' max='64200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64200/64200 30:16, Epoch 120/120]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>0.626239</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.586000</td>\n",
       "      <td>0.615488</td>\n",
       "      <td>0.074576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.549500</td>\n",
       "      <td>0.621807</td>\n",
       "      <td>0.150448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.648292</td>\n",
       "      <td>0.141881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.475300</td>\n",
       "      <td>0.704112</td>\n",
       "      <td>0.095184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.438300</td>\n",
       "      <td>0.772287</td>\n",
       "      <td>0.115828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.397600</td>\n",
       "      <td>0.818466</td>\n",
       "      <td>0.107498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.922398</td>\n",
       "      <td>0.083275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>1.014700</td>\n",
       "      <td>0.098630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.313500</td>\n",
       "      <td>1.210560</td>\n",
       "      <td>0.073775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.287900</td>\n",
       "      <td>1.281384</td>\n",
       "      <td>0.062322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.271800</td>\n",
       "      <td>1.284150</td>\n",
       "      <td>0.078657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.256900</td>\n",
       "      <td>1.455976</td>\n",
       "      <td>0.045211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.236600</td>\n",
       "      <td>1.392514</td>\n",
       "      <td>0.091350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>1.559503</td>\n",
       "      <td>0.076721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>1.559133</td>\n",
       "      <td>0.083185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.196900</td>\n",
       "      <td>1.769726</td>\n",
       "      <td>0.088532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>1.820280</td>\n",
       "      <td>0.075482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.193800</td>\n",
       "      <td>1.843353</td>\n",
       "      <td>0.091351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.185700</td>\n",
       "      <td>1.927733</td>\n",
       "      <td>0.095560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>2.122204</td>\n",
       "      <td>0.085802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.163200</td>\n",
       "      <td>2.092124</td>\n",
       "      <td>0.087399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>2.235852</td>\n",
       "      <td>0.114615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>2.431472</td>\n",
       "      <td>0.091938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>2.315363</td>\n",
       "      <td>0.083405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>2.552394</td>\n",
       "      <td>0.089284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>2.355726</td>\n",
       "      <td>0.090263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>2.629221</td>\n",
       "      <td>0.102755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>2.477520</td>\n",
       "      <td>0.115898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.139200</td>\n",
       "      <td>2.482110</td>\n",
       "      <td>0.098125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.134400</td>\n",
       "      <td>2.471556</td>\n",
       "      <td>0.114087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>2.603490</td>\n",
       "      <td>0.101892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>2.416688</td>\n",
       "      <td>0.107462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>2.575239</td>\n",
       "      <td>0.102845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>2.589165</td>\n",
       "      <td>0.117907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>2.536524</td>\n",
       "      <td>0.129941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>2.644918</td>\n",
       "      <td>0.119518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>2.586148</td>\n",
       "      <td>0.110268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>2.752091</td>\n",
       "      <td>0.132750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>2.820790</td>\n",
       "      <td>0.100444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.094100</td>\n",
       "      <td>2.772017</td>\n",
       "      <td>0.108745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>2.753795</td>\n",
       "      <td>0.119751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>2.744017</td>\n",
       "      <td>0.116851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>2.712177</td>\n",
       "      <td>0.119751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>2.776484</td>\n",
       "      <td>0.122970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>2.686026</td>\n",
       "      <td>0.121206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>2.749988</td>\n",
       "      <td>0.124122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>2.855480</td>\n",
       "      <td>0.147843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>2.927192</td>\n",
       "      <td>0.114126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>2.994707</td>\n",
       "      <td>0.107516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>2.961460</td>\n",
       "      <td>0.100008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>2.955514</td>\n",
       "      <td>0.086551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>3.206936</td>\n",
       "      <td>0.086778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>3.251505</td>\n",
       "      <td>0.081138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>3.084241</td>\n",
       "      <td>0.078132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>3.097894</td>\n",
       "      <td>0.087953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>2.894213</td>\n",
       "      <td>0.109646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>2.977931</td>\n",
       "      <td>0.112162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>3.009223</td>\n",
       "      <td>0.090263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>2.897733</td>\n",
       "      <td>0.098924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>2.900460</td>\n",
       "      <td>0.112886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>3.106919</td>\n",
       "      <td>0.099369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>3.104627</td>\n",
       "      <td>0.097384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>3.249587</td>\n",
       "      <td>0.074994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>3.306972</td>\n",
       "      <td>0.082820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.053400</td>\n",
       "      <td>3.428941</td>\n",
       "      <td>0.073175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>3.125073</td>\n",
       "      <td>0.089204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>3.140883</td>\n",
       "      <td>0.125517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>3.411273</td>\n",
       "      <td>0.110254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>3.206007</td>\n",
       "      <td>0.128988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>3.159681</td>\n",
       "      <td>0.112002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>3.221505</td>\n",
       "      <td>0.120373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>3.237694</td>\n",
       "      <td>0.116566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>3.472399</td>\n",
       "      <td>0.098638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>3.388316</td>\n",
       "      <td>0.096930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>3.353996</td>\n",
       "      <td>0.112988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>3.403385</td>\n",
       "      <td>0.109241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>3.548789</td>\n",
       "      <td>0.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>3.460414</td>\n",
       "      <td>0.083576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>3.292822</td>\n",
       "      <td>0.100856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>3.551200</td>\n",
       "      <td>0.078212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>3.552666</td>\n",
       "      <td>0.081138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>3.549016</td>\n",
       "      <td>0.082328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>3.547389</td>\n",
       "      <td>0.105065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>3.536988</td>\n",
       "      <td>0.094298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>3.604049</td>\n",
       "      <td>0.088400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>3.564139</td>\n",
       "      <td>0.077092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>3.648371</td>\n",
       "      <td>0.080579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>3.629692</td>\n",
       "      <td>0.090263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>3.720507</td>\n",
       "      <td>0.081779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>3.678098</td>\n",
       "      <td>0.090263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>3.734137</td>\n",
       "      <td>0.108379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>3.649858</td>\n",
       "      <td>0.098143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>3.603437</td>\n",
       "      <td>0.084692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>3.632665</td>\n",
       "      <td>0.112426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>3.619654</td>\n",
       "      <td>0.098924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>3.591036</td>\n",
       "      <td>0.092065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>3.587161</td>\n",
       "      <td>0.105928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>3.620893</td>\n",
       "      <td>0.104924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>3.674947</td>\n",
       "      <td>0.106184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>3.757465</td>\n",
       "      <td>0.096079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>3.651760</td>\n",
       "      <td>0.095162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>3.513567</td>\n",
       "      <td>0.112440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>3.613037</td>\n",
       "      <td>0.106054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>3.701953</td>\n",
       "      <td>0.093048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>3.648135</td>\n",
       "      <td>0.105806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>3.607770</td>\n",
       "      <td>0.099790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>3.626883</td>\n",
       "      <td>0.094155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>3.636060</td>\n",
       "      <td>0.110390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>3.654093</td>\n",
       "      <td>0.107458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>3.646016</td>\n",
       "      <td>0.101585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>3.665242</td>\n",
       "      <td>0.100048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>3.680930</td>\n",
       "      <td>0.101857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>3.686746</td>\n",
       "      <td>0.110390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>3.711853</td>\n",
       "      <td>0.104397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>3.701823</td>\n",
       "      <td>0.099790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>3.728597</td>\n",
       "      <td>0.097103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>3.728166</td>\n",
       "      <td>0.099917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>3.755483</td>\n",
       "      <td>0.097103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>3.752725</td>\n",
       "      <td>0.097103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=64200, training_loss=0.10841144086415894, metrics={'train_runtime': 1816.6181, 'train_samples_per_second': 564.852, 'train_steps_per_second': 35.34, 'total_flos': 594747984354972.0, 'train_loss': 0.10841144086415894, 'epoch': 120.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_sc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6218067407608032,\n",
       " 'eval_matthews_correlation': 0.15044770083461464,\n",
       " 'eval_runtime': 0.5725,\n",
       " 'eval_samples_per_second': 1821.942,\n",
       " 'eval_steps_per_second': 115.291,\n",
       " 'epoch': 120.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_sc.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\sc\\Model 03-21-2023 11-15-16 PM\\checkpoint-1605\n"
     ]
    }
   ],
   "source": [
    "print(trainer_sc.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1c2f54458d7f848ec1fcb01a8862cbba54f8bc5c8c8ff3352654112e2f5a13a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
