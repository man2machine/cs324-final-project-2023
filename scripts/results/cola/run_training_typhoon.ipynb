{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = \"C:/HF_CACHE/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from cs324_project.datasets import GlueDatasetTask, load_glue_dataset_info\n",
    "from cs324_project.models import ModelCheckpointName, load_classification_model, load_pretraining_model, load_tokenizer\n",
    "from cs324_project.masking import (\n",
    "    get_training_args_mlm, get_trainer_mlm, RandomMaskingConfig, WholeWordMaskingConfig, TyphoonMaskingConfig)\n",
    "from cs324_project.classification import get_training_args_sc, get_trainer_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ModelCheckpointName.TINYBERT_HUAWEI\n",
    "task = GlueDatasetTask.COLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/HF_CACHE/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c483fcc347c44a1c8aef20a1be5a6d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-51f5b2c7a7ff1e58.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-02d0d32fa3df3a08.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-37efad78792ce9c4.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-df985a2934c3ba2f.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-b2e1d3e57836d04c.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-598cd95f3828ee11.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenizer = load_tokenizer(model_name)\n",
    "dataset_info = load_glue_dataset_info(task, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune with masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertForMaskedLM: ['fit_denses.3.weight', 'fit_denses.4.bias', 'fit_denses.1.weight', 'fit_denses.1.bias', 'fit_denses.4.weight', 'fit_denses.2.bias', 'fit_denses.0.weight', 'fit_denses.3.bias', 'cls.seq_relationship.bias', 'fit_denses.2.weight', 'cls.seq_relationship.weight', 'fit_denses.0.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_mlm = load_pretraining_model(model_name, dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training arguments, model output dir: C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 10-50-09 PM\n"
     ]
    }
   ],
   "source": [
    "training_args_mlm = get_training_args_mlm(\n",
    "    masking_config=TyphoonMaskingConfig(),\n",
    "    num_epochs=80)\n",
    "trainer_mlm = get_trainer_mlm(\n",
    "    dataset_info=dataset_info,\n",
    "    mlm_args=training_args_mlm,\n",
    "    model=model_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42800' max='42800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42800/42800 30:54, Epoch 80/80]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.505100</td>\n",
       "      <td>4.834571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.591500</td>\n",
       "      <td>4.642968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.295500</td>\n",
       "      <td>4.421858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.083700</td>\n",
       "      <td>4.516644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.942600</td>\n",
       "      <td>4.207966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.759700</td>\n",
       "      <td>4.192620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.641000</td>\n",
       "      <td>4.135361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.506400</td>\n",
       "      <td>4.179695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.436700</td>\n",
       "      <td>4.132398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.325400</td>\n",
       "      <td>3.895990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.225800</td>\n",
       "      <td>4.065744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.140100</td>\n",
       "      <td>3.931153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.046400</td>\n",
       "      <td>4.102461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.970100</td>\n",
       "      <td>4.014813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.915900</td>\n",
       "      <td>3.914757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.835400</td>\n",
       "      <td>3.905765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.746500</td>\n",
       "      <td>3.972546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.713300</td>\n",
       "      <td>3.948856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.628800</td>\n",
       "      <td>3.868052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.548400</td>\n",
       "      <td>3.873571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.518500</td>\n",
       "      <td>3.898523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.439900</td>\n",
       "      <td>3.777555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.396300</td>\n",
       "      <td>3.898773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.336700</td>\n",
       "      <td>3.903463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.289900</td>\n",
       "      <td>3.950981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.232900</td>\n",
       "      <td>3.912084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.214700</td>\n",
       "      <td>3.812028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.149700</td>\n",
       "      <td>3.942201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.096000</td>\n",
       "      <td>3.951968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.092200</td>\n",
       "      <td>3.910682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.056800</td>\n",
       "      <td>3.846034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.004800</td>\n",
       "      <td>3.775199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.967600</td>\n",
       "      <td>3.787130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.908800</td>\n",
       "      <td>3.964094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.900400</td>\n",
       "      <td>3.703134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.881400</td>\n",
       "      <td>3.877395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.816400</td>\n",
       "      <td>3.922803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.810600</td>\n",
       "      <td>3.910222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.756600</td>\n",
       "      <td>3.932393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.742000</td>\n",
       "      <td>3.849874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.739000</td>\n",
       "      <td>3.878760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.715100</td>\n",
       "      <td>3.877382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.690500</td>\n",
       "      <td>3.914228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.619600</td>\n",
       "      <td>3.896923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.630700</td>\n",
       "      <td>3.943763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.596400</td>\n",
       "      <td>3.914893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.571800</td>\n",
       "      <td>3.909264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.558600</td>\n",
       "      <td>3.853917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.548100</td>\n",
       "      <td>3.900302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.511700</td>\n",
       "      <td>3.907348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.499900</td>\n",
       "      <td>4.005390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.480400</td>\n",
       "      <td>3.936771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.458100</td>\n",
       "      <td>3.914328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.447800</td>\n",
       "      <td>3.766107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.441900</td>\n",
       "      <td>3.961730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.420500</td>\n",
       "      <td>3.897585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.414600</td>\n",
       "      <td>4.055925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.390800</td>\n",
       "      <td>3.862678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.367300</td>\n",
       "      <td>3.917104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.367600</td>\n",
       "      <td>3.894908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.346000</td>\n",
       "      <td>3.895594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.326900</td>\n",
       "      <td>4.116427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.300900</td>\n",
       "      <td>3.992499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.304500</td>\n",
       "      <td>3.990324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.301300</td>\n",
       "      <td>3.970116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.293900</td>\n",
       "      <td>3.868470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.267700</td>\n",
       "      <td>3.908342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.258100</td>\n",
       "      <td>3.952684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.236000</td>\n",
       "      <td>3.992722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.240300</td>\n",
       "      <td>3.832720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.232800</td>\n",
       "      <td>3.957700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.215200</td>\n",
       "      <td>3.912616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.229800</td>\n",
       "      <td>3.944811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.223500</td>\n",
       "      <td>3.851608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.226700</td>\n",
       "      <td>3.957659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.190100</td>\n",
       "      <td>3.901605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.201500</td>\n",
       "      <td>4.034728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.193100</td>\n",
       "      <td>4.135753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.172900</td>\n",
       "      <td>4.080647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.186500</td>\n",
       "      <td>3.927309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=42800, training_loss=2.0736108327134746, metrics={'train_runtime': 1856.6716, 'train_samples_per_second': 368.444, 'train_steps_per_second': 23.052, 'total_flos': 399180875327136.0, 'train_loss': 2.0736108327134746, 'epoch': 80.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_mlm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.7931089401245117,\n",
       " 'eval_runtime': 0.6572,\n",
       " 'eval_samples_per_second': 1586.944,\n",
       " 'eval_steps_per_second': 100.42,\n",
       " 'epoch': 80.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_mlm.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 10-50-09 PM\\checkpoint-18725\n"
     ]
    }
   ],
   "source": [
    "print(trainer_mlm.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune on sequence classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 10-50-09 PM\\checkpoint-18725 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 10-50-09 PM\\checkpoint-18725 and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'bert.pooler.dense.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_sc = load_classification_model(trainer_mlm.state.best_model_checkpoint, dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training arguments, model output dir: C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\sc\\Model 03-21-2023 11-21-09 PM\n"
     ]
    }
   ],
   "source": [
    "training_args_sc = get_training_args_sc(\n",
    "    task,\n",
    "    learning_rate=2e-5,\n",
    "    num_epochs=120)\n",
    "trainer_sc = get_trainer_sc(\n",
    "    dataset_info=dataset_info,\n",
    "    model=model_sc,\n",
    "    training_args=training_args_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64200' max='64200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64200/64200 28:10, Epoch 120/120]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.605300</td>\n",
       "      <td>0.626629</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.582100</td>\n",
       "      <td>0.613550</td>\n",
       "      <td>0.058731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.546200</td>\n",
       "      <td>0.619160</td>\n",
       "      <td>0.159715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.507400</td>\n",
       "      <td>0.654687</td>\n",
       "      <td>0.137794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.465800</td>\n",
       "      <td>0.690929</td>\n",
       "      <td>0.142344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.427800</td>\n",
       "      <td>0.769951</td>\n",
       "      <td>0.100444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.827330</td>\n",
       "      <td>0.105785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.362000</td>\n",
       "      <td>0.878652</td>\n",
       "      <td>0.090918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.335300</td>\n",
       "      <td>0.955249</td>\n",
       "      <td>0.084465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.308100</td>\n",
       "      <td>1.049490</td>\n",
       "      <td>0.063192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.286800</td>\n",
       "      <td>1.063484</td>\n",
       "      <td>0.096390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.263400</td>\n",
       "      <td>1.160187</td>\n",
       "      <td>0.093245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.331741</td>\n",
       "      <td>0.061117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.231900</td>\n",
       "      <td>1.328969</td>\n",
       "      <td>0.080735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>1.357937</td>\n",
       "      <td>0.093365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.211300</td>\n",
       "      <td>1.401227</td>\n",
       "      <td>0.074679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.192900</td>\n",
       "      <td>1.476255</td>\n",
       "      <td>0.116851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>1.676213</td>\n",
       "      <td>0.102621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>1.670540</td>\n",
       "      <td>0.105687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>1.744028</td>\n",
       "      <td>0.096527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>1.862145</td>\n",
       "      <td>0.100747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.156300</td>\n",
       "      <td>1.883900</td>\n",
       "      <td>0.105926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>2.075662</td>\n",
       "      <td>0.094680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>1.928970</td>\n",
       "      <td>0.090308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>2.135633</td>\n",
       "      <td>0.076292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>2.216646</td>\n",
       "      <td>0.106329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>2.286107</td>\n",
       "      <td>0.071638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>2.361602</td>\n",
       "      <td>0.092599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>2.353283</td>\n",
       "      <td>0.095162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>2.477369</td>\n",
       "      <td>0.095292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>2.621943</td>\n",
       "      <td>0.083876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.133400</td>\n",
       "      <td>2.489254</td>\n",
       "      <td>0.089903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>2.788785</td>\n",
       "      <td>0.109838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>2.777966</td>\n",
       "      <td>0.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>2.829843</td>\n",
       "      <td>0.100182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>2.895277</td>\n",
       "      <td>0.105572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>2.799372</td>\n",
       "      <td>0.107324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>2.822217</td>\n",
       "      <td>0.097663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>2.996790</td>\n",
       "      <td>0.097443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>2.996975</td>\n",
       "      <td>0.086846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>2.760742</td>\n",
       "      <td>0.113961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>2.706011</td>\n",
       "      <td>0.115005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.084100</td>\n",
       "      <td>2.787402</td>\n",
       "      <td>0.118083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>2.972309</td>\n",
       "      <td>0.121280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>2.881264</td>\n",
       "      <td>0.126140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>2.906262</td>\n",
       "      <td>0.127050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>2.804346</td>\n",
       "      <td>0.113445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>2.937281</td>\n",
       "      <td>0.142003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>2.930056</td>\n",
       "      <td>0.150668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>2.796971</td>\n",
       "      <td>0.128490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>2.910356</td>\n",
       "      <td>0.119167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>2.766927</td>\n",
       "      <td>0.122434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>2.983827</td>\n",
       "      <td>0.120025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>3.043812</td>\n",
       "      <td>0.116027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>3.064059</td>\n",
       "      <td>0.130127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>2.974830</td>\n",
       "      <td>0.119409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>3.121897</td>\n",
       "      <td>0.105928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>3.092028</td>\n",
       "      <td>0.112788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>3.168254</td>\n",
       "      <td>0.107714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>2.887804</td>\n",
       "      <td>0.119596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>3.017754</td>\n",
       "      <td>0.096117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>2.845181</td>\n",
       "      <td>0.088248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>3.071754</td>\n",
       "      <td>0.095037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>2.904042</td>\n",
       "      <td>0.113445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>3.029518</td>\n",
       "      <td>0.095144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>2.945192</td>\n",
       "      <td>0.120025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>2.836910</td>\n",
       "      <td>0.142615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>2.842482</td>\n",
       "      <td>0.125468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>2.994775</td>\n",
       "      <td>0.114907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>3.040285</td>\n",
       "      <td>0.120280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>3.108474</td>\n",
       "      <td>0.121617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>2.967383</td>\n",
       "      <td>0.143366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>3.017569</td>\n",
       "      <td>0.114966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>3.166321</td>\n",
       "      <td>0.133342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>3.213967</td>\n",
       "      <td>0.118766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>3.177169</td>\n",
       "      <td>0.131446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>3.132116</td>\n",
       "      <td>0.131485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>3.188500</td>\n",
       "      <td>0.132927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>3.186476</td>\n",
       "      <td>0.137397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>3.179156</td>\n",
       "      <td>0.124169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>3.179799</td>\n",
       "      <td>0.134610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>3.278127</td>\n",
       "      <td>0.129987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>3.328776</td>\n",
       "      <td>0.122832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>3.321832</td>\n",
       "      <td>0.129990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>3.223393</td>\n",
       "      <td>0.128490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>3.154730</td>\n",
       "      <td>0.125444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>3.166085</td>\n",
       "      <td>0.117972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>3.279015</td>\n",
       "      <td>0.127087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>3.271221</td>\n",
       "      <td>0.125446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>3.287852</td>\n",
       "      <td>0.126991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>3.311578</td>\n",
       "      <td>0.134559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>3.408400</td>\n",
       "      <td>0.123126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>3.375363</td>\n",
       "      <td>0.143477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>3.350904</td>\n",
       "      <td>0.134487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>3.461771</td>\n",
       "      <td>0.139129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>3.383253</td>\n",
       "      <td>0.141867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>3.421553</td>\n",
       "      <td>0.123967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>3.493685</td>\n",
       "      <td>0.139079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>3.589107</td>\n",
       "      <td>0.149581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>3.444973</td>\n",
       "      <td>0.125447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>3.502646</td>\n",
       "      <td>0.140443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>3.450930</td>\n",
       "      <td>0.123952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>3.448528</td>\n",
       "      <td>0.137397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>3.433452</td>\n",
       "      <td>0.126973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>3.457492</td>\n",
       "      <td>0.147743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>3.403618</td>\n",
       "      <td>0.123988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>3.400022</td>\n",
       "      <td>0.133037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>3.348852</td>\n",
       "      <td>0.129966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>3.431807</td>\n",
       "      <td>0.137405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>3.401304</td>\n",
       "      <td>0.130016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>3.434041</td>\n",
       "      <td>0.138878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>3.414138</td>\n",
       "      <td>0.122445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>3.413116</td>\n",
       "      <td>0.120972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>3.453239</td>\n",
       "      <td>0.134431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>3.451179</td>\n",
       "      <td>0.132941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>3.447016</td>\n",
       "      <td>0.131439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>3.474929</td>\n",
       "      <td>0.131485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>3.474648</td>\n",
       "      <td>0.132941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>3.467439</td>\n",
       "      <td>0.137390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>3.470405</td>\n",
       "      <td>0.137390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=64200, training_loss=0.10616298128882673, metrics={'train_runtime': 1690.3374, 'train_samples_per_second': 607.05, 'train_steps_per_second': 37.981, 'total_flos': 594747984354972.0, 'train_loss': 0.10616298128882673, 'epoch': 120.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_sc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6191602945327759,\n",
       " 'eval_matthews_correlation': 0.15971484435137157,\n",
       " 'eval_runtime': 0.4618,\n",
       " 'eval_samples_per_second': 2258.735,\n",
       " 'eval_steps_per_second': 142.93,\n",
       " 'epoch': 120.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_sc.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\sc\\Model 03-21-2023 11-21-09 PM\\checkpoint-1605\n"
     ]
    }
   ],
   "source": [
    "print(trainer_sc.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1c2f54458d7f848ec1fcb01a8862cbba54f8bc5c8c8ff3352654112e2f5a13a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
