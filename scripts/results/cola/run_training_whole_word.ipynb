{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = \"C:/HF_CACHE/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from cs324_project.datasets import GlueDatasetTask, load_glue_dataset_info\n",
    "from cs324_project.models import ModelCheckpointName, load_classification_model, load_pretraining_model, load_tokenizer\n",
    "from cs324_project.masking import (\n",
    "    get_training_args_mlm, get_trainer_mlm, RandomMaskingConfig, WholeWordMaskingConfig, TyphoonMaskingConfig)\n",
    "from cs324_project.classification import get_training_args_sc, get_trainer_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ModelCheckpointName.TINYBERT_HUAWEI\n",
    "task = GlueDatasetTask.COLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/HF_CACHE/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0118033315da4aa5b8ea81b07ae737f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-51f5b2c7a7ff1e58.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-02d0d32fa3df3a08.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-37efad78792ce9c4.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-df985a2934c3ba2f.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-b2e1d3e57836d04c.arrow\n",
      "Loading cached processed dataset at C:\\HF_CACHE\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-598cd95f3828ee11.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenizer = load_tokenizer(model_name)\n",
    "dataset_info = load_glue_dataset_info(task, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune with masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'fit_denses.4.bias', 'cls.seq_relationship.weight', 'fit_denses.2.weight', 'fit_denses.3.bias', 'fit_denses.4.weight', 'fit_denses.0.weight', 'fit_denses.2.bias', 'fit_denses.0.bias', 'fit_denses.1.bias', 'fit_denses.3.weight', 'fit_denses.1.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_mlm = load_pretraining_model(model_name, dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training arguments, model output dir: C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 10-50-04 PM\n"
     ]
    }
   ],
   "source": [
    "training_args_mlm = get_training_args_mlm(\n",
    "    masking_config=WholeWordMaskingConfig(),\n",
    "    num_epochs=80)\n",
    "trainer_mlm = get_trainer_mlm(\n",
    "    dataset_info=dataset_info,\n",
    "    mlm_args=training_args_mlm,\n",
    "    model=model_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42800' max='42800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42800/42800 25:06, Epoch 80/80]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.476200</td>\n",
       "      <td>4.856486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.675000</td>\n",
       "      <td>4.588410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.394100</td>\n",
       "      <td>4.433332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.161900</td>\n",
       "      <td>4.360320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.028600</td>\n",
       "      <td>4.211881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.841200</td>\n",
       "      <td>4.306231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.716000</td>\n",
       "      <td>4.206958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.582400</td>\n",
       "      <td>4.104444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.478600</td>\n",
       "      <td>4.221748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.379100</td>\n",
       "      <td>4.090416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.343800</td>\n",
       "      <td>4.041897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.248600</td>\n",
       "      <td>4.040209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.172000</td>\n",
       "      <td>4.111246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.064200</td>\n",
       "      <td>3.880382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.964600</td>\n",
       "      <td>3.921483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.930900</td>\n",
       "      <td>3.961389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.841600</td>\n",
       "      <td>3.997656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.778800</td>\n",
       "      <td>3.889449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.725000</td>\n",
       "      <td>3.873467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.684700</td>\n",
       "      <td>3.998193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.584400</td>\n",
       "      <td>3.894971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.566400</td>\n",
       "      <td>3.945998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.506700</td>\n",
       "      <td>3.870136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.444700</td>\n",
       "      <td>3.887539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.381000</td>\n",
       "      <td>3.806280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.354000</td>\n",
       "      <td>3.840959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.293500</td>\n",
       "      <td>3.792630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.286500</td>\n",
       "      <td>3.836017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.190100</td>\n",
       "      <td>3.917659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.188500</td>\n",
       "      <td>3.846199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.182100</td>\n",
       "      <td>3.886284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.088600</td>\n",
       "      <td>3.826161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.098200</td>\n",
       "      <td>3.822362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.033300</td>\n",
       "      <td>3.936995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.025800</td>\n",
       "      <td>3.967729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.939300</td>\n",
       "      <td>3.925903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.941600</td>\n",
       "      <td>3.984417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.911100</td>\n",
       "      <td>3.966319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.910100</td>\n",
       "      <td>3.915002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.836800</td>\n",
       "      <td>3.835871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.829900</td>\n",
       "      <td>3.951886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.775500</td>\n",
       "      <td>4.008940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.758300</td>\n",
       "      <td>3.816374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.725900</td>\n",
       "      <td>3.902110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.706000</td>\n",
       "      <td>3.988783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.738300</td>\n",
       "      <td>3.790712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.664000</td>\n",
       "      <td>3.808654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.681100</td>\n",
       "      <td>3.834232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.611500</td>\n",
       "      <td>3.948453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.642100</td>\n",
       "      <td>3.952815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.569400</td>\n",
       "      <td>3.954460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.564700</td>\n",
       "      <td>3.987730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.564100</td>\n",
       "      <td>3.892281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.539400</td>\n",
       "      <td>3.840102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.517200</td>\n",
       "      <td>4.035010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.051082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.518200</td>\n",
       "      <td>4.014521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.493400</td>\n",
       "      <td>3.969174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.425500</td>\n",
       "      <td>3.989420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.437700</td>\n",
       "      <td>4.061902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.442100</td>\n",
       "      <td>3.929818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.432100</td>\n",
       "      <td>3.941849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.389300</td>\n",
       "      <td>4.135612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.387400</td>\n",
       "      <td>4.018697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.369800</td>\n",
       "      <td>4.063277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.422100</td>\n",
       "      <td>4.049465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.321000</td>\n",
       "      <td>3.965133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.335000</td>\n",
       "      <td>4.031628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.326800</td>\n",
       "      <td>3.919311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.360600</td>\n",
       "      <td>4.059878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.299900</td>\n",
       "      <td>4.077488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.301300</td>\n",
       "      <td>4.109407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.304000</td>\n",
       "      <td>4.076490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.296400</td>\n",
       "      <td>3.933022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.285500</td>\n",
       "      <td>3.969279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.279100</td>\n",
       "      <td>3.975666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.247600</td>\n",
       "      <td>4.022891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.280100</td>\n",
       "      <td>3.991887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.277400</td>\n",
       "      <td>4.028561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.278900</td>\n",
       "      <td>3.927089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=42800, training_loss=2.16435872871185, metrics={'train_runtime': 1509.0761, 'train_samples_per_second': 453.31, 'train_steps_per_second': 28.362, 'total_flos': 399180875327136.0, 'train_loss': 2.16435872871185, 'epoch': 80.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_mlm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.871267318725586,\n",
       " 'eval_runtime': 0.7061,\n",
       " 'eval_samples_per_second': 1477.109,\n",
       " 'eval_steps_per_second': 93.47,\n",
       " 'epoch': 80.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_mlm.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 10-50-04 PM\\checkpoint-24610\n"
     ]
    }
   ],
   "source": [
    "print(trainer_mlm.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune on sequence classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 10-50-04 PM\\checkpoint-24610 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\mlm\\Model 03-21-2023 10-50-04 PM\\checkpoint-24610 and are newly initialized: ['classifier.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_sc = load_classification_model(trainer_mlm.state.best_model_checkpoint, dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training arguments, model output dir: C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\sc\\Model 03-21-2023 11-15-14 PM\n"
     ]
    }
   ],
   "source": [
    "training_args_sc = get_training_args_sc(\n",
    "    task,\n",
    "    learning_rate=2e-5,\n",
    "    num_epochs=120)\n",
    "trainer_sc = get_trainer_sc(\n",
    "    dataset_info=dataset_info,\n",
    "    model=model_sc,\n",
    "    training_args=training_args_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64200' max='64200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64200/64200 30:11, Epoch 120/120]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.604700</td>\n",
       "      <td>0.628101</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.580800</td>\n",
       "      <td>0.628493</td>\n",
       "      <td>0.064130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.545700</td>\n",
       "      <td>0.667171</td>\n",
       "      <td>0.157594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.503800</td>\n",
       "      <td>0.714600</td>\n",
       "      <td>0.158868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.466800</td>\n",
       "      <td>0.769538</td>\n",
       "      <td>0.133485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.432100</td>\n",
       "      <td>0.795189</td>\n",
       "      <td>0.146047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.848036</td>\n",
       "      <td>0.136677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.362600</td>\n",
       "      <td>0.893386</td>\n",
       "      <td>0.127016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.332500</td>\n",
       "      <td>0.957512</td>\n",
       "      <td>0.158842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.986879</td>\n",
       "      <td>0.144543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.290700</td>\n",
       "      <td>1.067740</td>\n",
       "      <td>0.140273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.278700</td>\n",
       "      <td>1.106456</td>\n",
       "      <td>0.158761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.256900</td>\n",
       "      <td>1.106899</td>\n",
       "      <td>0.146854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>1.308364</td>\n",
       "      <td>0.149711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>1.244903</td>\n",
       "      <td>0.143368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.216100</td>\n",
       "      <td>1.459270</td>\n",
       "      <td>0.140987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>1.358223</td>\n",
       "      <td>0.147978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>1.446299</td>\n",
       "      <td>0.142218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>1.524993</td>\n",
       "      <td>0.163006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.183600</td>\n",
       "      <td>1.512604</td>\n",
       "      <td>0.171473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>1.572748</td>\n",
       "      <td>0.165854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>1.697737</td>\n",
       "      <td>0.149098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.163800</td>\n",
       "      <td>1.818848</td>\n",
       "      <td>0.174027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>1.859010</td>\n",
       "      <td>0.166089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.150900</td>\n",
       "      <td>1.967693</td>\n",
       "      <td>0.149068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>1.918313</td>\n",
       "      <td>0.186544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>1.933301</td>\n",
       "      <td>0.159588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>1.971141</td>\n",
       "      <td>0.188549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>2.020499</td>\n",
       "      <td>0.191483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>2.074111</td>\n",
       "      <td>0.149957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>2.117432</td>\n",
       "      <td>0.161061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>2.133697</td>\n",
       "      <td>0.177955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>2.190825</td>\n",
       "      <td>0.174318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>2.245032</td>\n",
       "      <td>0.169194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>2.231684</td>\n",
       "      <td>0.165920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>2.324332</td>\n",
       "      <td>0.165068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>2.419973</td>\n",
       "      <td>0.150362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.107100</td>\n",
       "      <td>2.353479</td>\n",
       "      <td>0.163849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>2.352989</td>\n",
       "      <td>0.168095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>2.237206</td>\n",
       "      <td>0.160840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>2.312377</td>\n",
       "      <td>0.168573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>2.375360</td>\n",
       "      <td>0.163908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>2.383991</td>\n",
       "      <td>0.152396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>2.389441</td>\n",
       "      <td>0.172808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.088300</td>\n",
       "      <td>2.421185</td>\n",
       "      <td>0.167901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>2.398812</td>\n",
       "      <td>0.166486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>2.437206</td>\n",
       "      <td>0.185516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>2.412740</td>\n",
       "      <td>0.176587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>2.415953</td>\n",
       "      <td>0.158127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>2.429509</td>\n",
       "      <td>0.156039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>2.462094</td>\n",
       "      <td>0.163021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>2.451331</td>\n",
       "      <td>0.130211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>2.593719</td>\n",
       "      <td>0.146610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>2.527767</td>\n",
       "      <td>0.157572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>2.506144</td>\n",
       "      <td>0.157439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>2.655839</td>\n",
       "      <td>0.157773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>2.663403</td>\n",
       "      <td>0.154724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>2.722709</td>\n",
       "      <td>0.130613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>2.663770</td>\n",
       "      <td>0.175751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>2.683003</td>\n",
       "      <td>0.166527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>2.695890</td>\n",
       "      <td>0.157773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>2.682657</td>\n",
       "      <td>0.165068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>2.669129</td>\n",
       "      <td>0.167157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>2.660693</td>\n",
       "      <td>0.162306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>2.794435</td>\n",
       "      <td>0.163690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>2.628874</td>\n",
       "      <td>0.174130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>2.700936</td>\n",
       "      <td>0.162001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>2.727700</td>\n",
       "      <td>0.155991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>2.689808</td>\n",
       "      <td>0.173964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>2.795445</td>\n",
       "      <td>0.181285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>2.795304</td>\n",
       "      <td>0.165783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>2.845194</td>\n",
       "      <td>0.172292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>2.772072</td>\n",
       "      <td>0.174139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>2.768025</td>\n",
       "      <td>0.186155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>2.734004</td>\n",
       "      <td>0.171253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>2.785539</td>\n",
       "      <td>0.190438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>2.736336</td>\n",
       "      <td>0.202023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>2.743723</td>\n",
       "      <td>0.191313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>2.817072</td>\n",
       "      <td>0.181844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>2.787449</td>\n",
       "      <td>0.168573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>2.859530</td>\n",
       "      <td>0.170291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>2.911821</td>\n",
       "      <td>0.183354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>2.853168</td>\n",
       "      <td>0.193126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>2.868162</td>\n",
       "      <td>0.185196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>2.975099</td>\n",
       "      <td>0.151770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>2.940108</td>\n",
       "      <td>0.163690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>2.942418</td>\n",
       "      <td>0.160586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>2.929861</td>\n",
       "      <td>0.154107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>2.910239</td>\n",
       "      <td>0.156944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>2.924664</td>\n",
       "      <td>0.160918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>2.926982</td>\n",
       "      <td>0.188753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>2.930511</td>\n",
       "      <td>0.172507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>3.040352</td>\n",
       "      <td>0.159525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>3.003186</td>\n",
       "      <td>0.169892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>3.003077</td>\n",
       "      <td>0.162377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>2.994142</td>\n",
       "      <td>0.174463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>2.979588</td>\n",
       "      <td>0.179706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>3.024132</td>\n",
       "      <td>0.172618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>3.018324</td>\n",
       "      <td>0.174392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>3.015535</td>\n",
       "      <td>0.169194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>2.998320</td>\n",
       "      <td>0.171898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>2.982735</td>\n",
       "      <td>0.171273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>2.989072</td>\n",
       "      <td>0.159585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>0.184556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>2.975047</td>\n",
       "      <td>0.173028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>2.999897</td>\n",
       "      <td>0.180586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>3.035959</td>\n",
       "      <td>0.179426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>3.014275</td>\n",
       "      <td>0.194623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>3.067536</td>\n",
       "      <td>0.169194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>3.070459</td>\n",
       "      <td>0.169925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>3.067896</td>\n",
       "      <td>0.166472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>3.073790</td>\n",
       "      <td>0.162306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>3.071578</td>\n",
       "      <td>0.165068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>3.076360</td>\n",
       "      <td>0.161633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>3.094597</td>\n",
       "      <td>0.162306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>3.073122</td>\n",
       "      <td>0.166441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>3.076489</td>\n",
       "      <td>0.169849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>3.074376</td>\n",
       "      <td>0.165783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>3.086329</td>\n",
       "      <td>0.163690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>3.085939</td>\n",
       "      <td>0.168489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=64200, training_loss=0.1086125812500808, metrics={'train_runtime': 1812.0224, 'train_samples_per_second': 566.284, 'train_steps_per_second': 35.43, 'total_flos': 594747984354972.0, 'train_loss': 0.1086125812500808, 'epoch': 120.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_sc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.7363359928131104,\n",
       " 'eval_matthews_correlation': 0.20202292868965951,\n",
       " 'eval_runtime': 0.6323,\n",
       " 'eval_samples_per_second': 1649.531,\n",
       " 'eval_steps_per_second': 104.381,\n",
       " 'epoch': 120.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_sc.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\Desktop\\Shahir\\cs324-final-project-2023\\models\\sc\\Model 03-21-2023 11-15-14 PM\\checkpoint-41195\n"
     ]
    }
   ],
   "source": [
    "print(trainer_sc.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1c2f54458d7f848ec1fcb01a8862cbba54f8bc5c8c8ff3352654112e2f5a13a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
